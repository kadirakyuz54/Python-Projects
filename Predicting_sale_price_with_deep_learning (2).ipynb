{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predicting sale price with deep learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2YesYwDYKK3"
      },
      "source": [
        "# In this project I am going to compare the performance of Linear regression and Deep Learning algorithms in predicting the sale price."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqbBWjSBljzm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10fee08d-9af9-4a83-d156-2ad2b976e490"
      },
      "source": [
        "# predicting sale price with deep learning\n",
        "from google.colab import drive\n",
        "drive.mount('/content/grive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/grive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnUY5YPBmSI6"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/grive/MyDrive/Colab Notebooks/diamonds.csv')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA8v1GaempEZ"
      },
      "source": [
        "df.head()\n",
        "df = df.drop(['Unnamed: 6','carat.1', 'Predicted price'], axis =1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbXh70538v-R"
      },
      "source": [
        "df = df.loc[0:49999:, ['carat', 'cut_ord', 'clarity_ord', 'price']]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "fsiTzQgAoO6Z",
        "outputId": "1c384c21-c65e-452d-da78-8668a7050ef8"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>carat</th>\n",
              "      <th>cut_ord</th>\n",
              "      <th>clarity_ord</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>50000.000000</td>\n",
              "      <td>50000.000000</td>\n",
              "      <td>50000.000000</td>\n",
              "      <td>50000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.798597</td>\n",
              "      <td>3.903980</td>\n",
              "      <td>4.126700</td>\n",
              "      <td>3939.103500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.474651</td>\n",
              "      <td>1.117043</td>\n",
              "      <td>1.665564</td>\n",
              "      <td>3995.879832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>326.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.400000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>948.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.700000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2402.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.040000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5331.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.010000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>18823.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              carat       cut_ord   clarity_ord         price\n",
              "count  50000.000000  50000.000000  50000.000000  50000.000000\n",
              "mean       0.798597      3.903980      4.126700   3939.103500\n",
              "std        0.474651      1.117043      1.665564   3995.879832\n",
              "min        0.200000      1.000000      1.000000    326.000000\n",
              "25%        0.400000      3.000000      3.000000    948.000000\n",
              "50%        0.700000      4.000000      4.000000   2402.500000\n",
              "75%        1.040000      5.000000      5.000000   5331.000000\n",
              "max        5.010000      5.000000      8.000000  18823.000000"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8D9hdK3CoaxB",
        "outputId": "de01fd63-ace7-486d-b200-303b7d82b6d7"
      },
      "source": [
        "df.var()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "carat          2.252939e-01\n",
              "cut_ord        1.247785e+00\n",
              "clarity_ord    2.774103e+00\n",
              "price          1.596706e+07\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyPUX1SpouNR"
      },
      "source": [
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "\n",
        "df['carat'] = df['carat'].astype(np.float32)\n",
        "df['cut_ord'] = df['cut_ord'].astype(np.float32)\n",
        "df['clarity_ord'] = df['clarity_ord'].astype(np.float32)\n",
        "df['price'] = df['price'].astype(np.float32)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_U42FZotoLw",
        "outputId": "75f73755-1a85-4b3a-daaa-70f6d5026e97"
      },
      "source": [
        "# Print the number of NaNs\n",
        "df.isnull().sum()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "carat          0\n",
              "cut_ord        0\n",
              "clarity_ord    0\n",
              "price          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qc-SJktw5sQ"
      },
      "source": [
        "predictors = df.drop('price', axis = 1)\n",
        "predictors = np.array(predictors)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owk-j53cxOoA"
      },
      "source": [
        "target = df.price\n",
        "target = np.array(target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOD-i_NoB2Qi",
        "outputId": "904ff4f7-8281-4198-8c48-69253bfc2953"
      },
      "source": [
        "# Import necessary modules\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create training and test sets\n",
        "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size = 0.30, random_state= 42)\n",
        "\n",
        "# Create the regressor: reg_all\n",
        "reg_all = LinearRegression()\n",
        "\n",
        "# Fit the regressor to the training data\n",
        "reg_all.fit(predictors_train, target_train)\n",
        "\n",
        "# Predict on the test data: y_pred\n",
        "target_pred = reg_all.predict(predictors_test)\n",
        "\n",
        "\n",
        "# Compute and print R^2 and RMSE\n",
        "print(\"R^2: {}\".format(reg_all.score(predictors_test, target_test)))\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(target_test, target_pred))\n",
        "\n",
        "print(\"Root Mean Squared Error: {}\".format(rmse))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2: 0.8849230974944802\n",
            "Root Mean Squared Error: 1328.0048828125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leQJKFONCz0h",
        "outputId": "f40cd34a-100d-40f1-9887-10b4a8c433b0"
      },
      "source": [
        ">>> print('intercept:', reg_all.intercept_)\n",
        "\n",
        ">>> print('slope:', reg_all.coef_)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "intercept: -5239.331\n",
            "slope: [8387.326    154.32529  456.85684]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "aXZ5oNo_8TBn",
        "outputId": "ce9c979d-2fce-4abd-e347-856278245d6e"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(df.corr(), square=True, cmap='RdYlGn')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f17206d65d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATQAAAD9CAYAAAAyEYtXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAa3klEQVR4nO3de5weZX338c93l8SADRGkKiUIQQPIIRWICNJHkYPGVkGpyMHKoUhsChUPqHkelSJPfV5iG2wVRFLEcKgiQcTVxhcHOVYOzXIKEAjGACUBpQJBCBXI7u/5Y64lw7LZnck992Hn/r5fr3ntzHVf98xvYPeX65pr5hpFBGZmddDT7gDMzKrihGZmteGEZma14YRmZrXhhGZmteGEZma14YRmZpWTdJ6kxyXds57PJembkpZLWiJp9yqO64RmZs2wAJg1yufvA6anZTZwdhUHdUIzs8pFxA3Ak6NUORi4IDK3AK+RtGWjx92o0R0UoTl71fJxhEd/U8vT4trLV7c7hKaZc9o27Q6haZ7+8pVq5Pul/k6/c+snyFpWQ+ZHxPwSh9sKeCS3vTKVPVZiH6/QkoRmZvWSkleZBNYSTmhmBoB6GmrglbUK2Dq3PTWVNcTX0MwMgJ6NegovFegDjkqjnXsBT0dEQ91NcAvNzJIqW2iSfgDsC2whaSXw98AEgIj4DrAI+HNgOfAccGwVx3VCMzMApOoSWkQcMcbnAZxQ2QETJzQzA1p+Da0pnNDMDHBCM7MacUIzs9qoaPSyrZzQzAxwC83MasQJzcxqo8rbNtrFCc3MALfQzKxGnNDMrDY8ymlmtVGHFlrhlCzppCJlZjY+qUeFl05Vpo159Ahlx1QUh5m1WR0S2phdTklHAEcC0yT15T6azOhzhpvZONLJiaqoItfQbiKb53sLYF6u/BlgSTOCMrPW6+ntgkGBiHgYeBjYu/nhmFm71KGFVmZQYC9JiyU9K+kFSQOSft/M4MysdbriGlrOmcDhwEJgJnAUsH0zgjKz1usZ/z3Oci9JiYjlQG9EDETE9xj9zchmNo70SoWXTlWmhfacpInAnZK+TjZQUIOcbmYAvR3clSyqTEL6WKp/IrCG7J16f9mMoMys9Sb2qvDSqQq10CT1Av8vIj4K/AH4SlOjMrOW6+SuZFGFWmgRMQBsk7qchUiaLalfUj9LH9/gAM2sNbrtGtoK4JfpaYE1Q4URccZIlSNiPjAfQHP2ikaCNLPm67ZraL8Gfpa+Mzm3mFkN9Kr4UoSkWZKWSVouae4In79R0rWS7pC0RNKfN3oOhVtoEeHrZmY1VmULLV13Pws4EFgJLJbUFxFLc9W+BFwSEWdL2glYBGzbyHELJzRJfwx8HtgZmDRUHhH7NRKAmXWGidU+y7knsDwiVgBIuhg4GMgntAA2TetTgEcbPWiZM/g34H5gGtko50PA4kYDMLPOUKbLmR/0S8vsYbvbCngkt70yleWdCvyVpJVkrbO/a/QcygwKvDYivivppIi4HrhekhOaWU2U6XLmB/0acASwICLmSdobuFDSLhExuKE7LJPQXkw/H5P0F2TNw8039MBm1lkqvh1jFdnN90OmprK840iPT0bEzZImkU1TtsH3eZVJaP8gaQrwWeBbZH3fT23ogc2ss1Sc0BYD0yVNI0tkh5NNFJv3X8D+wAJJbyG7Nv/fjRy0zDW0QwFFxD0R8W6y0YsPNXJwM+scVT76FBFryR6TvAK4j2w0815Jp0k6KFX7LHC8pLuAHwDHRERD96yWaaHNiIjVuYCflLRbIwc3s85R9Y21EbGI7GJ/vuyU3PpSYJ8qj1kmofVI2iwingKQtHnJ75tZB+vkR5qKKpOQ5gE3S1qYtg8Fvlp9SGbWDjV4pUCpJwUukNQPDN1Ie8iwu37NbBzrthbaUJ/XScyshurwcLqvgZkZQEdP3FiUE5qZAV3Y5TSz+qpBA80JzcwyPW6hmVlduIVmZrVRg0FOJzQzy0yoQRPNCc3MAHc5zaxG3OU0s9pwC83MasO3bRT06G/q+Z7hP3nD+P8FGMngiuPaHULTfPCca9sdQsea0E2zbZhZvfnRJzOrDQ8KmFlteFDAzGqjx9fQzKwufA3NzGrDo5xmVht1GBSoQU42syr0SoWXIiTNkrRM0nJJc9dT5yOSlkq6V9L3Gz0Ht9DMDKi2hSapFzgLOBBYCSyW1Jd/U5yk6cD/BvaJiKckva7R4zqhmRlQ+W0bewLLI2IFgKSLgYN5+VvjjgfOGnp5eUQ83uhB3eU0MyB7lrPoImm2pP7cMnvY7rYCHsltr0xledsD20v6paRbJM1q9BzGbKFJ2n20zyPi9kaDMLP2m1CizxkR84H5DR5yI2A6sC8wFbhB0q4RsbqRHY5lXvo5CZgJ3AUImAH0A3tv6MHNrHNUPNvGKmDr3PbUVJa3Erg1Il4EHpT0AFmCW7yhBx2zyxkR746IdwOPAbtHxMyI2APYbYQAzWycKtPlLGAxMF3SNEkTgcOBvmF1LidrnSFpC7Iu6IpGzqHMoMAOEXH30EZE3CPpLY0c3Mw6R4+qu6QeEWslnQhcAfQC50XEvZJOA/ojoi999h5JS4EB4HMR8UQjxy2T0O6WdC5wUdr+KLCkkYObWeeoeoLHiFgELBpWdkpuPYDPpKUSZRLaMcAc4KS0fQNwdlWBmFl7bVSDp9MLJbR0k9zP07W0bzQ3JDNrh54a3MVVKKFFxICkQUlTIuLpZgdlZq3Xbe8UeJbsOtpVwJqhwoj4ZOVRmVnLdVtCuywtZlZDVY5ytkvhhBYR56f7SbZPRcvSDXFmVgNd1UKTtC9wPvAQ2ZMCW0s6OiJuaE5oZtZKXTPKmcwD3hMRywAkbQ/8ANijGYGZWWt1VZcTmDCUzAAi4gFJE5oQk5m1QQ9d1OUE+kd4UqC/+pDMrB266hoa2VMCJwBDt2ncCHy78ojMrC3q0OUsfAYR8XxEnBERh6TlGxHx/NDnkn6Ur5+fAO6ihxqeiNLMmmyjnp7CS6eqcgru7fIb+QngHvvQ26PC45hZE9ShhVZlQnPSMhvHuu0ampnVWLeNco5l/P/XMOtidWihFe40SzppjLIvVBKRmbVFj3oKL52qTGRHj1B2zNBKRFzZcDRm1ja9Pb2Fl05V5DV2RwBHAtMk5V9yMBl4slmBmVlrdcsEjzeRvfFpC9a90g7gGfxOAbPaUAd3JYsaM6FFxMPAw/j9m2a11snXxooqM33QM6y712wiMAFYExGbNiMwM2stdUmXE4CImDy0LknAwcBezQjKzFqvDi20DTqDyFwOvLfieMysTXq1UeGlCEmzJC2TtFzS3FHq/aWkkDSz0XMo0+U8JLfZA8wE/tBoAGbWGaocFEivvjwLOBBYCSyW1BcRS4fVm0z2rt9bqzhumScFPpBbX0s2FfdBVQRhZu1X8W0bewLLI2IFgKSLyS5TLR1W7/8CpwOfq+KgZRJaD3BSRKxOAW5GdhvHX1cRiJm1V8W3bWwFPJLbXgm8/eXH0+7A1hHx75JantBmDCUzgIh4StJuVQRhZu1XZlBA0mxgdq5ofpoyrOj3e4AzyD1tVIVSLTRJm0XEUymgzUt+38w6WG+JV4Tk5ztcj1XA1rntqalsyGRgF+C67KYJ3gD0STooIjZ4av+yb326WdLCtH0o8NUNPbCZdZaK70NbDEyXNI0skR1O9gglABHxNNnTR9mxpeuAkxtJZlDuPrQLJPUD+6WiQ4aPWJjZ+FXlfWgRsVbSicAVQC9wXkTcK+k0oD8i+kbfw4Yp1WVMCcxJzKyGqn6WMyIWAYuGlZ2ynrr7VnFMXwMzM6B7Ztswsy7QFbNtmFl3KPpIUycb/2dgZpWow8PpTmhmBnTZ9EFmVm9uoRV07eWrx640Dg2uOK7dITRFz9cva3cITbPq0cF2h9A0mzT4fQ8KmFltKMaus65y08JoiBOamWUG1xav26FvsnNCM7NMjP/ueJH3cv6UdS9HeYWI8CSPZnXQDQkN+Kf08xCyKT4uSttHAL9tRlBm1gaDXZDQIuJ6AEnzIiL/EoOfptk3zKwOuqSFNuTVkrbLzRE+DXh1c8Iys5YrMyjQocoktE+RzS65gmzQdhtePgWvmY1n3dDlhJfm/54CTAd2TMX3R8TzzQrMzFqsW7qcETEo6fMRcQlwV5NjMrN26JaEllwt6WTgh8CaocKIeLLyqMys9bosoR2Wfp6QKwtgu+rCMbN2iRgoXLdDn3wq9ZKUac0MxMzabKCLRjklTQDmAO9MRdcB50TEi02Iy8xarcu6nGcDE4Bvp+2PpbKPVx2UmbVBlyW0t0XEn+a2r5HkEU+zuuiyhDYg6U0R8WsASdsBxa8imllnq8GNtWWmqPwccK2k6yRdD1wDfLY5YZlZy8Vg8aUASbMkLZO0XNLcET7/jKSlkpZI+oWkbRo9hTKjnL+QNB3YIRUtyz8pIOnAiLiq0YDMrE0qfJZTUi9wFnAgsBJYLKkvIpbmqt0BzIyI5yTNAb7OutvDNkipScQj4vmIWJKW4Y89nd5IIGbWZoODxZex7Qksj4gVEfECcDFwcL5CRFwbEc+lzVuAqY2eQpVvRejUe+3MrIgSXU5JsyX155bhE1VsBTyS216ZytbnOODnjZ5ClVNwl3nFgpl1mhKjnBExH5hfxWEl/RUwE3hXo/vyOwXMLFPtKOcqYOvc9tRU9jKSDgC+CLyritl7qkxoD1W4LzNrtbWV3oW1GJieJoJdBRwOHJmvIGk34BxgVkQ8XsVBC19Dk3SbpBMkbTbS5xFxSBUBmVmbVDgoEBFrgROBK4D7gEsi4l5Jp0kaerHSPwJ/BCyUdKekvkZPoexsG8eSDb/2A98DrowIXzszq4PBav+UI2IRsGhY2Sm59QMqPSAlWmgRsTwivghsD3wfOA94WNJXJG0+vH5+FOQaVlcXsZk1R7W3bbRFqds2JM0A5pE1FX8EHAr8nuypgZeJiPkRMTMiZu7Ha6qI1cyaqQYJrcz0QbcBq4HvAnNzIxK3StqnGcGZWQtV3OVshzLX0A4deoXdEEnTIuJBDwiY1UC1o5xtUabLeWnBMjMbj7qhyylpR2BnYIqkfEtsU2BSswIzsxbr4ERVVJEu5w7A+4HXAB/IlT8DHN+MoMys9crcgdWpD26PmdAi4ifATyTtHRE3tyAmM2uHbmihpRcMfx04UtIRwz+PiE82JTIza60aDAoU6XLel372NzMQM2uzbmihRcRP0+yTu0bEyS2IyczaoRsSGkBEDPjmWbOa67Iba4eehl8IrBkqjIjLKo/KzFqvW1poySTgCWC/XFkATmhmddBNCS0ijm1mIGbWZl0yygmApElkLzLYmdwTAhHx102Iy8xarQYttDLPcl4IvAF4L3A92RzhzzQjKDNrg8EovnSoMgntzRHxZWBNRJwP/AXw9uaEZWYt1w0Pp+e8mH6ulrQL8BvgddWHZGbtEAOd2/IqqkxCm59ekPJloI/s5QanjP4VMxs3OrgrWVSZUc5z0+r1wHbNCcfM2iVe7NyuZFFFHk7/zGifR8QZ1YVjZm3TJV3Oyeln8MppkMb/fwEzywx0QQstIr4CIOl84KSIWJ22NyN7A5SZ1UBUfA1N0izgX4Be4NyI+Nqwz18FXADsQfYU0mER8VAjxyxz28aMoWQGEBFPAbs1cnAz6yADUXwZQ5qh5yzgfcBOwBGSdhpW7TjgqYh4M/AN4PRGT6FMQutJrTIA0suFy4ySmlkHixcHCy8F7Aksj4gVEfECcDFw8LA6BwPnp/VLgf0lNTS7d5mENA+4WdLCtH0o8NVGDm5mHaTEDbOSZgOzc0XzI2J+bnsr4JHc9kpeeSP+S3UiYq2kp4HXAr8rEfXLlLlt4wJJ/aybbeOQiFha5LtzTttmQ2LreB8859p2h9AUqx4d/xeH12erPynTKRlfGr4CVmKUMyWv+WNWbLFSXcaUwAolMTMbXyoeFFgFbJ3bnprKRqqzUtJGwBSywYENVt9/rsysnAoHBYDFwHRJ0yRNBA4ne8Iorw84Oq1/GLgmyrxLbwS+qG9mmQpvrE3XxE4EriC7beO8iLhX0mlAf0T0Ad8FLpS0HHiSLOk1xAnNzACIF6ud4DEiFgGLhpWdklv/A9ngYmWc0MwMqP7G2nZwQjOzTJc8y2lm3cAtNDOri26b4NHM6swtNDOri6pHOdvBCc3MMu5ymlld+LYNM6sNDwqYWW24hWZmtTHQDW99MrPuEB38RvSinNDMDKjHNbRS86FJ2kbSAWl9Y0mTx/qOmY0PMRiFl05VOKFJOp7sRQbnpKKpwOXNCMrMWi8GovDSqcp0OU8ge5PLrQAR8StJr2tKVGbWcp3c8iqqTEJ7PiJeGHrLVJoDfPz/FzAzoPtGOa+X9H+AjSUdCPwt8NPmhGVmrVaHFlqZQYG5wH8DdwOfIJta90vNCMrMWq8OgwJlWmgbk73o4F/hpVe9bww814zAzKy1Ovlif1FlWmi/IEtgQzYGrq42HDNrlxgcLLx0qjIttEkR8ezQRkQ8K2mTJsRkZm1QhxZamYS2RtLuEXE7gKQ9gP9pTlhm1moDazu35VVUmS7np4CFkm6U9B/AD4ET11dZ0mxJ/ZL6X+hf2WicZtZkrbqxVtLmkq6S9Kv0c7MR6rxV0s2S7pW0RNJhRfZdOKFFxGJgR2AO8DfAWyLitlHqz4+ImRExc+LMqUUPY2Zt0sJRzrnALyJiOtm1+bkj1HkOOCoidgZmAf8s6TVj7XjMLqek/SLiGkmHDPtoe0lExGVjx29mna6F19AOBvZN6+cD1wFfeFksEQ/k1h+V9Djwx8Dq0XZc5Brau4BrgA+M8FkATmhmNdDC+8teHxGPpfXfAK8frbKkPYGJwK/H2vGYCS0i/l5SD/DziLikQLBmNg4Nlnj0SdJsYHauaH5EzM99fjXwhhG++sX8RkSEpPVmUklbAhcCR0fEmAEWGuWMiEFJnwec0MxqarBECy0lr/mjfH7A+j6T9FtJW0bEYylhPb6eepsC/w58MSJuKRJXmVHOqyWdLGnrNEqxuaTNS3zfzDrY4GDxpUF9wNFp/WjgJ8MrSJoI/Bi4ICIuLbrjMvehHUZ2zexvh5VvV2IfZtahWvgAwNeASyQdBzwMfARA0kzgbyLi46nsncBrJR2TvndMRNw52o7LJLSdyJLZn5ElthuB75T4vpl1sFYltIh4Ath/hPJ+4ONp/SLgorL7LpPQzgd+D3wzbR+Zyj5S9qBm1nk6eBKNwsoktF0iYqfc9rWSllYdkJm1x9q17Y6gcWUGBW6XtNfQhqS3A/3Vh2Rm7dDCQYGmKdNC2wO4SdJ/pe03Assk3U12O8mMyqMzs5bp5ERVVJmENqtpUZhZ23VVQouIh5sZiJm1V1clNDOrNyc0M6uNgS6bsdbMaswtNDOrDSc0M6sNJzQzqw0nNDOrjTo8+uSEZmaAW2hmViPdNtuGmdWYW2hmVhtOaGZWG3VIaIqoQcc5R9Ls/Ou06qSu5+bzsqqUmeBxvJg9dpVxq67n5vOyStQxoZlZl3JCM7PaqGNCq/M1i7qem8/LKlG7QQEz6151bKGZWZdyQjOz2ujKhCZpW0lHtjsOqy9Jp0k6oN1xdJvaJjRJoz0FsS3QkQmtmclW0nWSZja4j1MlnVzyOwdJmpvWPyhpp0ZiKHnsfSX9rFXHS8fsjYhTIuLqVh7XxklCk3SUpCWS7pJ0oaQPSLpV0h2Srpb0+lTv1PT5L4ELU3K4UdLtaXlH2uXXgP8l6U5Jn27biY1sWypItmMk9JaRtFFE9EXE11LRB4GmJTRJvc3ad9r/tpLul/Rvku6TdKmkTSQ9JOl0SbcDh0paIOnD6Ttvk3RT+v39T0mTJfVK+kdJi9Pv9ieaGXfXiIiOXoCdgQeALdL25sBmrBuh/TgwL62fCtwGbJy2NwEmpfXpQH9a3xf4WYvP4yhgCXAXcCGwAPhw7vNn089bgKeBO4FPr2dfk4DvAXcDdwDvTuXHAH3ANcD1wMbAxcB9wI+BW4GZDcZ9KnBy+ux4YHH67EfAJql8AfCddLwzUlxnAu8AngQeTOf3JuD23LGm57dHiGX/dL53A+cBr0rlDwGnA7cDh5O9FPv+tP3NKv9fk/2DE8A+afs84OQUw+dz9RYAHwYmAiuAt6XyTcmeoZ4NfCmVvQroB6a1++9tvC8d8a/4GPYDFkbE7wAi4klJuwI/lLQl2S/Mg7n6fRHxP2l9AnCmpLcCA8D2LYz7JZJ2Br4EvCMifidpc7I/9JHMJUsY7x9llycAERG7StoRuFLS0LntDsxI/50+AzwXEW+RNIPsD7zRuD+Zq3JZRPxrqvsPwHHAt9JnU9P3BiQdQxbwTZL6yBLMpel7T0t6a0TcCRxLlqhHimUSWZLYPyIekHQBMAf451TliYjYPdX7FdnvzXLgh2XOuaBHIuKXaf0i1v03GelYOwCPRcRigIj4fTqf9wAzhlpxwBSyhP7gCPuwgsZFl3ME3wLOjIhdgU+QtViGrMmtfxr4LfCnwEyy5NcOr0jKDe7vz8j+kIiI+4GHWZesr8rt/525ekvIWlpVxr1L6tLfDXyUrDU9ZGFEDBQ4xrnAsamreBjw/fXU2wF4MCIeSNvnk53fkKFksmOq96vImj8XFYihrOE3bw5trxlecRQC/i4i3pqWaRFxZTXhda/xkNCuIbsm8VqA1EqYAqxKnx89ynenkP3rOAh8DBi6vvIMMLk54Ra2lvTfX1IP1SXbMn9UjVoAnJj+YfkK6/+HZTQ/At4HvB+4LSKe2MBYWnneb5S0d1o/EviPUeouA7aU9DaAdP1sI+AKYI6kCal8e0mvbmbQ3aDjE1pE3At8Fbhe0l1kXbVTgYWSbgN+N8rXvw0cnb63I+t+6ZcAA+kibSsGBUZKyg8Be6TPDyLrHkOxZHsjWYuI1NV8I9kfznA3kAYYJO0CzKgg7rzJwGPpj/KjBff5svOLiD+Q/XGfzXq6m8kyYFtJb07bHyO7Tjjc/anem9L2EQXjKmMZcIKk+8iu5569vooR8QJZy/Nb6ffwKrLEfy6wFLhd0j3AOXh+wsa1+yJetyxkLcl7yC6gLwBeTzYAcBfZBe2hQYEJZInkLjZsUODMXL38oMBlbNigwPC4T2XdoMAcsms+/0l2GWBBKl/Aywc8XooL2IfsD/kO4E2pbC9gJdA7RiyjDQpskauXHxT4F6ofFLin3b9PXkZe/CyntV26r21KRHy53bGMRdK2ZAlylzaHYiNwQrO2kvRjsts39os0+GC2oZzQOpik95J1R/MejIgPtSOeVklJbtqw4i9ExBXtiMfGDyc0M6uNjh/lNDMrygnNzGrDCc3MasMJzcxq4/8D1nVFKAa5lzcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl9inMlExagR",
        "outputId": "5a8bcd3e-e9c5-42f7-c18d-40f676e95f0d"
      },
      "source": [
        "# Import EarlyStopping\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Import necessary modules\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Save the number of columns in predictors: n_cols\n",
        "n_cols = predictors.shape[1]\n",
        "input_shape = (n_cols,)\n",
        "\n",
        "input_shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwvC9m8Jxr4R"
      },
      "source": [
        "# Specify the model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(128, activation='relu', input_shape = input_shape,))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxOaAs2tyXjr",
        "outputId": "c9a537a4-e904-4e97-dace-cb4d43dd8c51"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 8)                 264       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 11,121\n",
            "Trainable params: 11,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4dNDghWzExZ"
      },
      "source": [
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYc2qJbyJTdQ"
      },
      "source": [
        "# Create training and test sets\n",
        "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size = 0.30, random_state= 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TkElhBCByJ1",
        "outputId": "1c762be2-6357-4d5c-fbb9-f6a78425f338"
      },
      "source": [
        "# Import the EarlyStopping and ModelCheckpoint callbacks\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Early stop on validation accuracy\n",
        "monitor_val_loss = EarlyStopping(monitor = 'val_loss', patience = 5)\n",
        "\n",
        "# Save the best model as best_banknote_model.hdf5\n",
        "modelCheckpoint = ModelCheckpoint('best_diamonds_model.hdf5', save_best_only = True)\n",
        "\n",
        "# Fit your model for a stupid amount of epochs\n",
        "h_callback = model.fit(predictors_train, target_train,\n",
        "                    epochs = 1000,\n",
        "                    callbacks = [monitor_val_loss, modelCheckpoint],\n",
        "                    validation_data = (predictors_test, target_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1094/1094 [==============================] - 3s 2ms/step - loss: 11463453.0000 - val_loss: 2482072.5000\n",
            "Epoch 2/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1938133.1250 - val_loss: 1537728.3750\n",
            "Epoch 3/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1527701.2500 - val_loss: 1399395.5000\n",
            "Epoch 4/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1453191.8750 - val_loss: 1364616.6250\n",
            "Epoch 5/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1409910.6250 - val_loss: 1309798.3750\n",
            "Epoch 6/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1376546.6250 - val_loss: 1283195.3750\n",
            "Epoch 7/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1357826.6250 - val_loss: 1294285.8750\n",
            "Epoch 8/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1335770.1250 - val_loss: 1326546.0000\n",
            "Epoch 9/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1328277.6250 - val_loss: 1326414.7500\n",
            "Epoch 10/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1320168.0000 - val_loss: 1295743.5000\n",
            "Epoch 11/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1317563.8750 - val_loss: 1276706.5000\n",
            "Epoch 12/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1311289.2500 - val_loss: 1213642.6250\n",
            "Epoch 13/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1313618.5000 - val_loss: 1265433.5000\n",
            "Epoch 14/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1305132.7500 - val_loss: 1234799.6250\n",
            "Epoch 15/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1301984.6250 - val_loss: 1211880.3750\n",
            "Epoch 16/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1298433.6250 - val_loss: 1219633.8750\n",
            "Epoch 17/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1293489.3750 - val_loss: 1263763.1250\n",
            "Epoch 18/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1291377.7500 - val_loss: 1210420.6250\n",
            "Epoch 19/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1281709.8750 - val_loss: 1199237.2500\n",
            "Epoch 20/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1275397.2500 - val_loss: 1192803.6250\n",
            "Epoch 21/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1266317.8750 - val_loss: 1175976.1250\n",
            "Epoch 22/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1267473.1250 - val_loss: 1173507.1250\n",
            "Epoch 23/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1258640.1250 - val_loss: 1169470.0000\n",
            "Epoch 24/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1239897.0000 - val_loss: 1157950.1250\n",
            "Epoch 25/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1235182.0000 - val_loss: 1171418.0000\n",
            "Epoch 26/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1227806.5000 - val_loss: 1174836.7500\n",
            "Epoch 27/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1229129.3750 - val_loss: 1140608.2500\n",
            "Epoch 28/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1221915.0000 - val_loss: 1156857.1250\n",
            "Epoch 29/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1225976.6250 - val_loss: 1150734.5000\n",
            "Epoch 30/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1219837.3750 - val_loss: 1149328.5000\n",
            "Epoch 31/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1214009.0000 - val_loss: 1181867.7500\n",
            "Epoch 32/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1214015.7500 - val_loss: 1130469.5000\n",
            "Epoch 33/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1215567.8750 - val_loss: 1127882.7500\n",
            "Epoch 34/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1204999.3750 - val_loss: 1149220.7500\n",
            "Epoch 35/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1206394.1250 - val_loss: 1126970.0000\n",
            "Epoch 36/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1196185.6250 - val_loss: 1184587.2500\n",
            "Epoch 37/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1200139.5000 - val_loss: 1143065.2500\n",
            "Epoch 38/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1198878.2500 - val_loss: 1199154.1250\n",
            "Epoch 39/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1193584.2500 - val_loss: 1252489.5000\n",
            "Epoch 40/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1188107.2500 - val_loss: 1124692.5000\n",
            "Epoch 41/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1184173.8750 - val_loss: 1124098.7500\n",
            "Epoch 42/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1181475.0000 - val_loss: 1166435.6250\n",
            "Epoch 43/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1175667.1250 - val_loss: 1122098.1250\n",
            "Epoch 44/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1176314.0000 - val_loss: 1110604.6250\n",
            "Epoch 45/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1177076.0000 - val_loss: 1172558.2500\n",
            "Epoch 46/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1167864.7500 - val_loss: 1112727.1250\n",
            "Epoch 47/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1166984.6250 - val_loss: 1098556.2500\n",
            "Epoch 48/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1162040.8750 - val_loss: 1145868.5000\n",
            "Epoch 49/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1161848.7500 - val_loss: 1090995.2500\n",
            "Epoch 50/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1160664.5000 - val_loss: 1109606.6250\n",
            "Epoch 51/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1158912.6250 - val_loss: 1095257.3750\n",
            "Epoch 52/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1155634.6250 - val_loss: 1104189.0000\n",
            "Epoch 53/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1151965.5000 - val_loss: 1117793.0000\n",
            "Epoch 54/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1159006.0000 - val_loss: 1089899.5000\n",
            "Epoch 55/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1145780.0000 - val_loss: 1125490.8750\n",
            "Epoch 56/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1147905.8750 - val_loss: 1147939.1250\n",
            "Epoch 57/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1144401.5000 - val_loss: 1098631.2500\n",
            "Epoch 58/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1147606.1250 - val_loss: 1090915.8750\n",
            "Epoch 59/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1146057.7500 - val_loss: 1081355.2500\n",
            "Epoch 60/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1139590.5000 - val_loss: 1093755.1250\n",
            "Epoch 61/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1139276.5000 - val_loss: 1109784.5000\n",
            "Epoch 62/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1137046.1250 - val_loss: 1102216.2500\n",
            "Epoch 63/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1135956.5000 - val_loss: 1077651.2500\n",
            "Epoch 64/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1134395.0000 - val_loss: 1177499.3750\n",
            "Epoch 65/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1133455.8750 - val_loss: 1102657.7500\n",
            "Epoch 66/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1131623.7500 - val_loss: 1189653.8750\n",
            "Epoch 67/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1127983.0000 - val_loss: 1076922.3750\n",
            "Epoch 68/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1128156.5000 - val_loss: 1072248.3750\n",
            "Epoch 69/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1128409.2500 - val_loss: 1073762.2500\n",
            "Epoch 70/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1124886.7500 - val_loss: 1072756.3750\n",
            "Epoch 71/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1127034.5000 - val_loss: 1068759.1250\n",
            "Epoch 72/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1122633.1250 - val_loss: 1141775.8750\n",
            "Epoch 73/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1125972.2500 - val_loss: 1094084.6250\n",
            "Epoch 74/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1120150.5000 - val_loss: 1076557.5000\n",
            "Epoch 75/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1127294.0000 - val_loss: 1075969.8750\n",
            "Epoch 76/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1122892.7500 - val_loss: 1068109.8750\n",
            "Epoch 77/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1113906.7500 - val_loss: 1064637.0000\n",
            "Epoch 78/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1113447.5000 - val_loss: 1089832.2500\n",
            "Epoch 79/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1113741.8750 - val_loss: 1122336.2500\n",
            "Epoch 80/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1109165.1250 - val_loss: 1063672.2500\n",
            "Epoch 81/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1105596.0000 - val_loss: 1083116.6250\n",
            "Epoch 82/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1110062.5000 - val_loss: 1082869.8750\n",
            "Epoch 83/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1107289.7500 - val_loss: 1059338.6250\n",
            "Epoch 84/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1103504.5000 - val_loss: 1061648.8750\n",
            "Epoch 85/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1098334.1250 - val_loss: 1063672.5000\n",
            "Epoch 86/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1097731.3750 - val_loss: 1048134.5000\n",
            "Epoch 87/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1098350.1250 - val_loss: 1055384.2500\n",
            "Epoch 88/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1094618.5000 - val_loss: 1052675.1250\n",
            "Epoch 89/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1096778.3750 - val_loss: 1057498.1250\n",
            "Epoch 90/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1094869.1250 - val_loss: 1076074.6250\n",
            "Epoch 91/1000\n",
            "1094/1094 [==============================] - 2s 2ms/step - loss: 1081911.2500 - val_loss: 1053042.8750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "1j1b7NFEtv45",
        "outputId": "61a3d05a-e0c3-4ee4-8b0a-07d0a199b315"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.plot(h_callback.history['val_loss'], label = 'Validation loss')\n",
        "plt.plot(h_callback.history['loss'], label= 'Training loss')\n",
        "plt.title('Model loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHLrCzHYCB6N"
      },
      "source": [
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "my_model = load_model('best_diamonds_model.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYHcMzhoDOMV",
        "outputId": "abfad9a9-1997-4bf0-fb3b-4f1d316d6a4a"
      },
      "source": [
        "preds = my_model.predict(predictors_test)\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5369.937  ],\n",
              "       [3062.2864 ],\n",
              "       [1550.7408 ],\n",
              "       ...,\n",
              "       [ 615.96063],\n",
              "       [1862.7834 ],\n",
              "       [ 803.30444]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejn7XsGlCMlc",
        "outputId": "5aee02ee-074e-4ec6-891e-205e8585fff1"
      },
      "source": [
        "target_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6884., 3212., 1424., ...,  696., 1224.,  723.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVTt4d84KnG2",
        "outputId": "c9708a0b-a7ad-44be-ffca-adff6c80a2ed"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from math import sqrt\n",
        "\n",
        "\n",
        "\n",
        "mse = mean_squared_error(target_test, preds)\n",
        "\n",
        "\n",
        "rmse = sqrt(mse)\n",
        "\n",
        "print('RMSE: %f' % rmse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 1023.784432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx7k3zHuLTqW"
      },
      "source": [
        "Deep learning algorithm with some optimization results in 20,8 % better performance than Linear Regression. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-A5m1KM6NBv"
      },
      "source": [
        "from keras.layers import BatchNormalization\n",
        "\n",
        "\n",
        "# Specify the model\n",
        "model_b = Sequential()\n",
        "\n",
        "model_b.add(Dense(128, activation='relu', input_shape = input_shape,))\n",
        "model_b.add(BatchNormalization())\n",
        "model_b.add(Dense(64, activation='relu'))\n",
        "model_b.add(BatchNormalization())\n",
        "model_b.add(Dense(32, activation='relu'))\n",
        "model_b.add(BatchNormalization())\n",
        "model_b.add(Dense(8, activation='relu'))\n",
        "model_b.add(BatchNormalization())\n",
        "model_b.add(Dense(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-CuZd4o8kY8",
        "outputId": "619b39fb-0037-4b45-9efa-fc8bf35e296c"
      },
      "source": [
        "model_b.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 8)                 264       \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 8)                 32        \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 12,049\n",
            "Trainable params: 11,585\n",
            "Non-trainable params: 464\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC26wByV8vPg"
      },
      "source": [
        "# Create training and test sets\n",
        "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size = 0.30, random_state= 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1REP2eca9Mot"
      },
      "source": [
        "# Compile the model\n",
        "model_b.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11LNsNNG86O0",
        "outputId": "a16e2cff-078b-4bd0-82c2-fd660d5d4535"
      },
      "source": [
        "# Import the EarlyStopping and ModelCheckpoint callbacks\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Early stop on validation accuracy\n",
        "monitor_val_loss = EarlyStopping(monitor = 'val_loss', patience = 5)\n",
        "\n",
        "# Save the best model as best_banknote_model.hdf5\n",
        "modelCheckpoint = ModelCheckpoint('best_diamonds_model_b.hdf5', save_best_only = True)\n",
        "\n",
        "# Fit your model for a stupid amount of epochs\n",
        "h_callback = model_b.fit(predictors_train, target_train,\n",
        "                    epochs = 1000,\n",
        "                    callbacks = [monitor_val_loss, modelCheckpoint],\n",
        "                    validation_data = (predictors_test, target_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1094/1094 [==============================] - 4s 3ms/step - loss: 31856708.0000 - val_loss: 29675256.0000\n",
            "Epoch 2/1000\n",
            "1094/1094 [==============================] - 3s 3ms/step - loss: 31166192.0000 - val_loss: 28915346.0000\n",
            "Epoch 3/1000\n",
            "1094/1094 [==============================] - 3s 2ms/step - loss: 30007094.0000 - val_loss: 27446446.0000\n",
            "Epoch 4/1000\n",
            "1094/1094 [==============================] - 3s 2ms/step - loss: 28511360.0000 - val_loss: 25872832.0000\n",
            "Epoch 5/1000\n",
            "1094/1094 [==============================] - 3s 2ms/step - loss: 26749022.0000 - val_loss: 23632592.0000\n",
            "Epoch 6/1000\n",
            "1094/1094 [==============================] - 3s 2ms/step - loss: 24795374.0000 - val_loss: 22539404.0000\n",
            "Epoch 7/1000\n",
            "1094/1094 [==============================] - 3s 3ms/step - loss: 22681048.0000 - val_loss: 20268600.0000\n",
            "Epoch 8/1000\n",
            "1094/1094 [==============================] - 3s 3ms/step - loss: 20466664.0000 - val_loss: 17926318.0000\n",
            "Epoch 9/1000\n",
            "1094/1094 [==============================] - 3s 2ms/step - loss: 18170282.0000 - val_loss: 15759174.0000\n",
            "Epoch 10/1000\n",
            "1094/1094 [==============================] - 3s 2ms/step - loss: 15870387.0000 - val_loss: 13230836.0000\n",
            "Epoch 11/1000\n",
            "1094/1094 [==============================] - 3s 3ms/step - loss: 13643710.0000 - val_loss: 11260121.0000\n",
            "Epoch 12/1000\n",
            "1094/1094 [==============================] - 3s 2ms/step - loss: 11462742.0000 - val_loss: 9485830.0000\n",
            "Epoch 13/1000\n",
            "1094/1094 [==============================] - 3s 2ms/step - loss: 9454159.0000 - val_loss: 7410493.0000\n",
            "Epoch 14/1000\n",
            "1094/1094 [==============================] - 3s 3ms/step - loss: 7604905.0000 - val_loss: 5791267.0000\n",
            "Epoch 15/1000\n",
            "1094/1094 [==============================] - 3s 2ms/step - loss: 5969155.5000 - val_loss: 4181121.0000\n",
            "Epoch 16/1000\n",
            "1094/1094 [==============================] - 3s 2ms/step - loss: 4717169.5000 - val_loss: 3006065.0000\n",
            "Epoch 17/1000\n",
            "1094/1094 [==============================] - 3s 3ms/step - loss: 3679898.2500 - val_loss: 2272483.7500\n",
            "Epoch 18/1000\n",
            "1094/1094 [==============================] - 3s 2ms/step - loss: 2939767.7500 - val_loss: 1765717.0000\n",
            "Epoch 19/1000\n",
            "1094/1094 [==============================] - 3s 3ms/step - loss: 2447633.0000 - val_loss: 1269296.6250\n",
            "Epoch 20/1000\n",
            "1094/1094 [==============================] - 3s 2ms/step - loss: 2186535.2500 - val_loss: 1139268.6250\n",
            "Epoch 21/1000\n",
            "1094/1094 [==============================] - 3s 2ms/step - loss: 2002137.2500 - val_loss: 1212484.3750\n",
            "Epoch 22/1000\n",
            "1094/1094 [==============================] - 3s 3ms/step - loss: 1937342.2500 - val_loss: 1174844.1250\n",
            "Epoch 23/1000\n",
            "1094/1094 [==============================] - 3s 2ms/step - loss: 1839894.7500 - val_loss: 1024129.6875\n",
            "Epoch 24/1000\n",
            "1094/1094 [==============================] - 3s 3ms/step - loss: 1749284.7500 - val_loss: 1009154.4375\n",
            "Epoch 25/1000\n",
            "1094/1094 [==============================] - 3s 3ms/step - loss: 1692887.6250 - val_loss: 1091129.5000\n",
            "Epoch 26/1000\n",
            "1094/1094 [==============================] - 3s 3ms/step - loss: 1661492.1250 - val_loss: 1102622.8750\n",
            "Epoch 27/1000\n",
            "1094/1094 [==============================] - 3s 3ms/step - loss: 1642785.1250 - val_loss: 1040757.1875\n",
            "Epoch 28/1000\n",
            "1094/1094 [==============================] - 3s 2ms/step - loss: 1636421.7500 - val_loss: 1083694.6250\n",
            "Epoch 29/1000\n",
            "1094/1094 [==============================] - 3s 2ms/step - loss: 1618245.0000 - val_loss: 1040444.9375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fDGNw4t9Cez"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "my_model2 = load_model('best_diamonds_model_b.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "difSC3PA96cM",
        "outputId": "0c3e1ff3-2627-47d7-d143-98785ad0b685"
      },
      "source": [
        "preds = my_model2.predict(predictors_test)\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5303.8394],\n",
              "       [3029.9883],\n",
              "       [1395.98  ],\n",
              "       ...,\n",
              "       [ 579.6655],\n",
              "       [1695.1681],\n",
              "       [ 980.5603]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPajk7l8-z-0",
        "outputId": "4f43239f-e55b-4b43-c7c6-aaa6a37e03f8"
      },
      "source": [
        "target_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6884., 3212., 1424., ...,  696., 1224.,  723.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx9ms3ab-6h7",
        "outputId": "72e3feaf-6693-4587-8f03-3984570b2999"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from math import sqrt\n",
        "\n",
        "\n",
        "\n",
        "mse = mean_squared_error(target_test, preds)\n",
        "\n",
        "\n",
        "rmse = sqrt(mse)\n",
        "\n",
        "print('RMSE: %f' % rmse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 1004.566729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apmhbP8E-_JE"
      },
      "source": [
        "# Deep learning with batch optimization performs even better with 24,4 % performance increase than the Linear regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mdAxiuJYkst"
      },
      "source": [
        "## RMSE with Linear Regression, 1328\n",
        "## RMSE with Deep Learning, 1023.78\n",
        "## RMSE with Deep Learning and Batch Normalization, 1004.56"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc4Pbojwi7Jk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}